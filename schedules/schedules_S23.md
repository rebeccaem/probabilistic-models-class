# Detailed list / Schedule of lectures / Topics

| |Mon|Wed|Fri|
|-|-|-|-|
|Week 0: Jan 16-20 | No class | 1 (Snow day) | 2 (Introductions) |
|Week 1: Jan 23-27 (Probability) | 3 | 4* | 5† |
|Week 2: Jan 30-Feb 3 (Probability) | 6  | 7**  | 8† (HW1 given) |
|Week 3: Feb 6-10 (Bayesian Statistics)  | 9  | 10  | 11††  |
|Week 4: Feb 13-17 (Bayesian Statistics)  | 12  | 13  | 14† (HW2 given, HW1 due)|
|Week 5: Feb 20-24 (Graphical Models)  | 15  | 16  | 17††  |
|Week 6: Feb 27-Mar 3 (Graphical Models) | 18  | 19  |  20† (HW3 given, HW2 due) |
|Week 7: Mar 6-10 (Misc Materials Week)  |  21 | 22  | 23†  |
|Week 8: Mar 13-17 (Inference)  | 24  | 25  | 26† (HW4 given, HW3 due) |
|Week 9: Mar 20-24 (Inference)  | 27 | 28  | 29†*** (review final project) |
|Week 10: Mar 27-31 (Spring Break) | No class  | No class  | No class  |
|Week 11: Apr 3-7 (Information Theory)  | 30  | 31  | 32† (HW5 given, HW4 due) |
|Week 12: Apr 10-14 (Information Theory)  | 33  |  34 | 35††  |
|Week 13: Apr 17-21 (Prediction)  | 36  |  37 | 38† (short HW6 given, HW5 due) |
|Week 14: Apr 24-28 (Advanced Graphical Models) |  39 | 40  | 41††  |
|Week 15: May 1-3 (TBD) | 42  | 43 (short HW6 due)  |  No class  |
|Week 16: Project presentations during final slot | -  | -  |  -  |


Legend: 
* `*` means last day to add a class (without instructor approval), `**` is last day to drop a class (without a W), `***` is last day to withdraw from a class (student receives a W)  
* `†` means lab class, `††` means guest lecture

### Detailed content of class, Spring 2023:
1. Snow day, class canceled
2. Introductions
    - syllabus review
    - join slack
    - in-class activity (ICA): meet two people and tell me about them, due in a week
3. Lecture: discrete probability intro
    - probability tables, conditioning (example 1.1.2 Barber)
    - how much information to define probability distribution with d variables, each with k_i states?
4. Lecture:
   - definitions
   - independence and conditional independence
   - motivation for probabilistic graphical models
5. Intro to software tools
   - finish counter-examples from class 4
   - Bernoulli and Binomial distributions
6. Lecture: Continuous distributions
   - multivariate normal (MVN)
   - concentration of measure in high dimensions
7. Lecture: Bayes' Rule
   - likelihood for a physics-based model
8. Lab class
   - MVN
   - start homework 1 together
9. Naive Bayes classifier
   - ICA (check Canvas! due in 2 days)

### Coming up:
11. Research talk: Tzu-Chi (Statistical community detection)
12. Lecture
13. Lecture


<!-- **11.** Guest lecture: Tzu-Chi (statistical community detection) -->
<!-- **16.** Guest lecture: Tyler Scott (Google Brain, stochastic embeddings) -->
<!-- **22.** Paper discussion -->
<!-- **33.** Guest lecture: Teo and Rileigh (advanced topics in inference) -->
<!-- **39.** Guest lecture: Nuttida Rungratsameetaweemana (recurrent neural network / how the brain processes information) -->

